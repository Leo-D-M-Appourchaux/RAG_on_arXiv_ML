{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the keys of ArXiv-tables entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'arxiv_id', 'page', 'bounding_box', 'latex_content', 'extracted_content', 'similarity_score', 'table_image', 'page_image'])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"staghado/ArXiv-tables\", split=\"train\")\n",
    "\n",
    "# Check available keys in first entry\n",
    "print(dataset[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the first entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table 0 LaTeX]\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\scriptsize\n",
      "    \\begin{tabular}{|p{3cm}|p{3cm}|p{4cm}|p{3cm}|}\n",
      "      \\hline\n",
      "      \\hline\n",
      "      \\multicolumn{4}{c}{Details of Experiments for the Employed Data Set}\\\\\n",
      "      \\cline{1-4}\n",
      "      \\emph{Domain} & \\emph{Raw Features} & \\emph{Response} & \\emph{Data Set Cardinality}\\\\\n",
      "      \\hline\n",
      "      Australian Credit Scoring & 16 & Desired credit approval of individuals based on characteristics & 690\\\\\\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{\\small Data set descriptions for the experiments used to validate the efficacy of the proposed algorithm. We summarize here the domain of the application, the input features to the algorithm, the response variable we wish to predict and the number of examples provided in the data.}\n",
      "  \\end{table}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load from Hugging Face\n",
    "dataset = load_dataset(\"staghado/ArXiv-tables\", split=\"train\")\n",
    "\n",
    "# Extract LaTeX from each entry\n",
    "for i, entry in enumerate(dataset):\n",
    "    latex_code = entry[\"latex_content\"]\n",
    "    print(f\"[Table {i} LaTeX]\")\n",
    "    print(latex_code)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tabular count: 11\n",
      "Entries with most tabulars:\n",
      "\n",
      "--- Entry 1187 has 11 tabulars ---\n",
      "\n",
      "\\begin{table}[h!]\n",
      "\\centering\n",
      "\\caption[Comparison of movement data libraries.]{Comparison of movement data libraries. Packages are predominantly available open source in R and Python and they are compared with regards to their focus, documentation and functionality. While other movement analysis libraries already provide well-maintained and documented code with rich functionality for trajectory analysis, only Trackintel provides robust and flexible methods to aggregate trajectories into locations, trips and tours. \\\\\n",
      "(\\checkmark / \\halfcheckmark / x : available / partially available / not available)}\n",
      "\\resizebox{\\textwidth}{!}{\n",
      "% \\begin{tabular}{@{}l|llp{9cm}@{}}\n",
      "% \\toprule\n",
      "% Library & \n",
      "% \\rot{Documentation score} & \\rot{Coverage}                    & \\rot{Open source} \\\\\n",
      "% \\midrule\n",
      "% Trackintel &\n",
      "% \\checkmark & X & X \\\\\n",
      "% \\bottomrule\n",
      "% \\end{tabular}\n",
      "\n",
      "\\begin{tabular}{l|lclllllllllllll}\n",
      "\\toprule\n",
      "                                      \\textbf{Package name} &                                 \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"staghado/ArXiv-tables\", split=\"train\")\n",
    "\n",
    "# Track max count\n",
    "max_count = 0\n",
    "top_entries = []\n",
    "\n",
    "for i, entry in enumerate(dataset):\n",
    "    latex = entry[\"latex_content\"]\n",
    "    count = len(re.findall(r'\\\\begin{tabular}', latex))\n",
    "\n",
    "    if count > max_count:\n",
    "        max_count = count\n",
    "        top_entries = [(i, count, latex)]\n",
    "    elif count == max_count:\n",
    "        top_entries.append((i, count, latex))\n",
    "\n",
    "print(f\"Max tabular count: {max_count}\")\n",
    "print(f\"Entries with most tabulars:\")\n",
    "for idx, cnt, code in top_entries:\n",
    "    print(f\"\\n--- Entry {idx} has {cnt} tabulars ---\\n\")\n",
    "    print(code[:1000])  # preview first 1000 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def add_column_to_outermost_tabular(latex_code):\n",
    "    lines = latex_code.splitlines()\n",
    "    new_lines = []\n",
    "    nest = 0\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Start of a tabular block\n",
    "        if r'\\begin{tabular}' in stripped:\n",
    "            nest += 1\n",
    "            if nest == 1:\n",
    "                # Add an extra column (e.g., 'l' alignment)\n",
    "                line = re.sub(r'{([^}]*)}', lambda m: '{' + m.group(1) + 'l}', line, count=1)\n",
    "\n",
    "        # End of tabular block\n",
    "        elif r'\\end{tabular}' in stripped:\n",
    "            if nest == 1:\n",
    "                pass  # could mark end for outermost if needed\n",
    "            nest -= 1\n",
    "\n",
    "        # Modify rows in outermost tabular only\n",
    "        if nest == 1 and '&' in line and r'\\\\' in line:\n",
    "            parts = line.split('&')\n",
    "            parts.insert(-1, ' NEW ')  # insert before last cell\n",
    "            line = ' & '.join(parts)\n",
    "\n",
    "        new_lines.append(line)\n",
    "\n",
    "    return '\\n'.join(new_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Table 0: Original ---\n",
      "\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\scriptsize\n",
      "    \\begin{tabular}{|p{3cm}|p{3cm}|p{4cm}|p{3cm}|}\n",
      "      \\hline\n",
      "      \\hline\n",
      "      \\multicolumn{4}{c}{Details of Experiments for the Employed Data Set}\\\\\n",
      "      \\cline{1-4}\n",
      "      \\emph{Domain} & \\emph{Raw Features} & \\emph{Response} & \\emph{Data Set Cardinality}\\\\\n",
      "      \\hline\n",
      "      Australian Credit Scoring & 16 & Desired credit approval of individuals based on characteristics & 690\\\\\\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{\\small Data set descriptions for the experiments used to validate the efficacy of the proposed algorithm. We summarize here the domain of the application, the input features to the algorithm, the response variable we wish to predict and the number of examples provided in the data.}\n",
      "  \\end{table}\n",
      "\n",
      "--- Table 0: Modified ---\n",
      "\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\scriptsize\n",
      "    \\begin{tabularl}{|p{3cm}|p{3cm}|p{4cm}|p{3cm}|}\n",
      "      \\hline\n",
      "      \\hline\n",
      "      \\multicolumn{4}{c}{Details of Experiments for the Employed Data Set}\\\\\n",
      "      \\cline{1-4}\n",
      "      \\emph{Domain}  &  \\emph{Raw Features}  &  \\emph{Response}  &  NEW  &  \\emph{Data Set Cardinality}\\\\\n",
      "      \\hline\n",
      "      Australian Credit Scoring  &  16  &  Desired credit approval of individuals based on characteristics  &  NEW  &  690\\\\\\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{\\small Data set descriptions for the experiments used to validate the efficacy of the proposed algorithm. We summarize here the domain of the application, the input features to the algorithm, the response variable we wish to predict and the number of examples provided in the data.}\n",
      "  \\end{table}\n",
      "\n",
      "--- Table 1: Original ---\n",
      "\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\scriptsize\n",
      "    \\begin{tabular}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}\n",
      "      \\hline\n",
      "      \\hline\n",
      "      \\multicolumn{5}{c}{Details of Experiments for the Variable Threshold Algorithm}\\\\\n",
      "      \\cline{1-5}\n",
      "      \\emph{Statistic} & \\emph{Average} & \\emph{Minimum} & \\emph{Maximum} & \\emph{Standard Deviation}\\\\\n",
      "      \\hline\n",
      "      Predictive Accuracy of Random Forest & {\\vspace{0mm}$85\\%$} & {\\vspace{0mm}$81\\%$} & {\\vspace{0mm}$90\\%$} & {\\vspace{0mm}$3.24\\%$}\\\\\\hline\n",
      "      Convergence Time of Optimization Algorithm & {\\vspace{0mm}$10$} & {\\vspace{0mm}$7$} & {\\vspace{0mm}$12$} & {\\vspace{0mm}$2.2$}\\\\\\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{\\small We present here some relevant statistics related to our experiments in parameter optimization. Notice that in the predict\n",
      "\n",
      "--- Table 1: Modified ---\n",
      "\n",
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\scriptsize\n",
      "    \\begin{tabularl}{|p{3cm}|p{2cm}|p{2cm}|p{2cm}|p{2cm}|}\n",
      "      \\hline\n",
      "      \\hline\n",
      "      \\multicolumn{5}{c}{Details of Experiments for the Variable Threshold Algorithm}\\\\\n",
      "      \\cline{1-5}\n",
      "      \\emph{Statistic}  &  \\emph{Average}  &  \\emph{Minimum}  &  \\emph{Maximum}  &  NEW  &  \\emph{Standard Deviation}\\\\\n",
      "      \\hline\n",
      "      Predictive Accuracy of Random Forest  &  {\\vspace{0mm}$85\\%$}  &  {\\vspace{0mm}$81\\%$}  &  {\\vspace{0mm}$90\\%$}  &  NEW  &  {\\vspace{0mm}$3.24\\%$}\\\\\\hline\n",
      "      Convergence Time of Optimization Algorithm  &  {\\vspace{0mm}$10$}  &  {\\vspace{0mm}$7$}  &  {\\vspace{0mm}$12$}  &  NEW  &  {\\vspace{0mm}$2.2$}\\\\\\hline\n",
      "    \\end{tabular}\n",
      "    \\caption{\\small We present here some relevant statistics related to our experiments in p\n",
      "\n",
      "--- Table 2: Original ---\n",
      "\n",
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabular}{c|c|c|c|c|c}\n",
      "    \\hline\n",
      "    \\multirow{3}{*}{Data}& \\multirow{3}{*}{Number of rows}& \\multicolumn{4}{c}{TabSynDex Score}\\\\ \\cline{3-6}\n",
      "         &  & \\multicolumn{4}{c}{\\% of real data treated as synthetic}\\\\ \\cline{3-6}\n",
      "        & &10\\%&25\\%&50\\%&100\\%\\\\ \\hline\n",
      "        Concrete~\\cite{concrete_data} &1030&0.768&0.869&0.914&0.894\\\\ \\hline\n",
      "        News Popularity~\\cite{news_data} &39644&0.891&0.916&0.901&0.898\\\\ \\hline\n",
      "        Wine Quality~\\cite{wine_data} &4898&0.867&0.911&0.925&0.938\\\\ \\hline\n",
      "        Power Plant~\\cite{electrical_data} &9568&0.946&0.961&0.981&0.969\\\\ \\hline\n",
      "    \\end{tabular}\n",
      "}\n",
      "\\caption{Experiment for sanity check of the TabSynDex metric for tabular data synthesis evaluation. The real dataset is divided in\n",
      "\n",
      "--- Table 2: Modified ---\n",
      "\n",
      "\\begin{table}[t]\n",
      "\\centering\n",
      "\\resizebox{\\columnwidth}{!}{\n",
      "\\begin{tabularl}{c|c|c|c|c|c}\n",
      "    \\hline\n",
      "    \\multirow{3}{*}{Data} &  \\multirow{3}{*}{Number of rows} &  NEW  &  \\multicolumn{4}{c}{TabSynDex Score}\\\\ \\cline{3-6}\n",
      "          &    &  NEW  &  \\multicolumn{4}{c}{\\% of real data treated as synthetic}\\\\ \\cline{3-6}\n",
      "         &   & 10\\% & 25\\% & 50\\% &  NEW  & 100\\%\\\\ \\hline\n",
      "        Concrete~\\cite{concrete_data}  & 1030 & 0.768 & 0.869 & 0.914 &  NEW  & 0.894\\\\ \\hline\n",
      "        News Popularity~\\cite{news_data}  & 39644 & 0.891 & 0.916 & 0.901 &  NEW  & 0.898\\\\ \\hline\n",
      "        Wine Quality~\\cite{wine_data}  & 4898 & 0.867 & 0.911 & 0.925 &  NEW  & 0.938\\\\ \\hline\n",
      "        Power Plant~\\cite{electrical_data}  & 9568 & 0.946 & 0.961 & 0.981 &  NEW  & 0.969\\\\ \\hline\n",
      "    \\end{tabular}\n",
      "}\n",
      "\\caption{Experi\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "# Function to add column only to outermost tabular\n",
    "def add_column_to_outermost_tabular(latex_code):\n",
    "    lines = latex_code.splitlines()\n",
    "    new_lines = []\n",
    "    nest = 0\n",
    "\n",
    "    for line in lines:\n",
    "        stripped = line.strip()\n",
    "\n",
    "        # Start of a tabular block\n",
    "        if r'\\begin{tabular}' in stripped:\n",
    "            nest += 1\n",
    "            if nest == 1:\n",
    "                # Add an extra column (e.g., 'l' alignment)\n",
    "                line = re.sub(r'{([^}]*)}', lambda m: '{' + m.group(1) + 'l}', line, count=1)\n",
    "\n",
    "        # End of tabular block\n",
    "        elif r'\\end{tabular}' in stripped:\n",
    "            nest -= 1\n",
    "\n",
    "        # Modify rows in outermost tabular only\n",
    "        if nest == 1 and '&' in line and r'\\\\' in line:\n",
    "            parts = line.split('&')\n",
    "            parts.insert(-1, ' NEW ')  # insert a new column value\n",
    "            line = ' & '.join(parts)\n",
    "\n",
    "        new_lines.append(line)\n",
    "\n",
    "    return '\\n'.join(new_lines)\n",
    "\n",
    "# Load dataset\n",
    "dataset = load_dataset(\"staghado/ArXiv-tables\", split=\"train\")\n",
    "\n",
    "# Process the first 3 entries\n",
    "for i in range(3):\n",
    "    original = dataset[i][\"latex_content\"]\n",
    "    modified = add_column_to_outermost_tabular(original)\n",
    "\n",
    "    print(f\"\\n--- Table {i}: Original ---\\n\")\n",
    "    print(original[:800])\n",
    "    \n",
    "    print(f\"\\n--- Table {i}: Modified ---\\n\")\n",
    "    print(modified[:800])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
