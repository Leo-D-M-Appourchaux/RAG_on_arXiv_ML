\begin{table}[htbp]
% \caption{Comparison of traditional machine learning algorithms. Notation: $m$-number of training samples; $n$-input dimension; $c$-number of classes.}
% \centering
% \begin{tabular}{ m{2.1cm}<{\centering}|m{1.8cm}<{\centering}| m{3.2cm}<{\centering}|m{2.8cm}<{\centering}|m{3.0cm}<{\centering}}
% \toprule
% Algorithm & Model size & Optimization & Training complexity & Inference complexity\\
% \noalign{
% \hrule height 2pt
% }
% Decision tree &$\mathcal{O}(m)$ &- &$\mathcal{O}(mnlog(m))$ & $\mathcal{O}(log(m))$\\
% \hline
% Random forest & $\mathcal{O}(N_{tree}m)$ &- &$\mathcal{O}(N_{tree}mnlog(m))$ & $\mathcal{O}(N_{tree}log(m))$\\
% \hline
% SVM & $\mathcal{O}(n)$ & gradient descent &$\mathcal{O}(m^2n)$ &$\mathcal{O}(m_{sv}n)$ \\
% \hline
% Logistic regression & $\mathcal{O}(n)$ &Newton-Raphson &$\mathcal{O}(mn^2+n^3)$ & $\mathcal{O}(n)$ \\
% \hline
% kNN &$\mathcal{O}(mn)$&- & - &$\mathcal{O}(mn)$ \\
% \hline
% Naive Bayes &$\mathcal{O}(nc)$ &-&$\mathcal{O}(mn+nc)$ & $\mathcal{O}(nc)$ \\
% \hline
% Linear regression &$\mathcal{O}(n)$ &matrix inversion &$\mathcal{O}(mn^2+n^3)$ &$\mathcal{O}(n)$ \\
% \noalign{
% \hrule height 2pt
% }
% k-Means &- &- &$\mathcal{O}(mnc)$ &- \\
% \hline
% EM &-&-&$\mathcal{O}(mn^2+n^3)$ & -\\
% \noalign{
% \hrule height 2pt
% }
% PCA &- &eigen-decomposition &$\mathcal{O}(mn^2+n^3)$ & -\\
% \bottomrule
% \end{tabular}
% \label{table:MLcompare}
% \end{table}